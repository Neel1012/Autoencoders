{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import Model,layers\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 10) (80,)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = 10 * rng.rand(100, 10)\n",
    "Y = 0.5 + np.dot(X, [1.5, -2., 0.0001,3.,10.,-0.55,8.,6.,1.,0.05])\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2) # Generating train and test dataset\n",
    "\n",
    "min_val_x = X.min()\n",
    "max_val_x = X.max()\n",
    "\n",
    "min_val_y = Y.min()\n",
    "max_val_y = Y.max()\n",
    "\n",
    "X_train = (X_train - min_val_x) / (max_val_x - min_val_x)\n",
    "X_test = (X_test - min_val_x) / (max_val_x - min_val_x)\n",
    "\n",
    "Y_train = (Y_train - min_val_y) / (max_val_y - min_val_y)\n",
    "Y_test = (Y_test - min_val_y) / (max_val_y - min_val_y)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=0.0\n",
    "std = 0.20 * np.std(X_train) # for %20 Gaussian noise\n",
    "def gaussian_noise(x,mu,std):\n",
    "    noise = np.random.normal(mu, std, size = x.shape)\n",
    "    x_n = x + noise\n",
    "    return x_n \n",
    "\n",
    "X_train_n = gaussian_noise(X_train,mu,std)\n",
    "X_test_n = gaussian_noise(X_test,mu,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation = 'relu', kernel_initializer = 'he_normal', input_shape = (X_train.shape[1],)))\n",
    "model.add(Dense(8, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0983 - mae: 1.0098\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.9647 - mae: 0.9440\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8417 - mae: 0.8794\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.7345 - mae: 0.8185\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.6399 - mae: 0.7597\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.5550 - mae: 0.7042\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4815 - mae: 0.6517\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.4145 - mae: 0.6011\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3560 - mae: 0.5526\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.3053 - mae: 0.5078\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2604 - mae: 0.4664\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2236 - mae: 0.4283\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1905 - mae: 0.3939\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1640 - mae: 0.3613\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1425 - mae: 0.3335\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 505us/step - loss: 0.1236 - mae: 0.3061\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.1085 - mae: 0.2837\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0953 - mae: 0.2640\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0853 - mae: 0.2477\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0757 - mae: 0.2340\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0693 - mae: 0.2236\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0636 - mae: 0.2145\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0592 - mae: 0.2062\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0556 - mae: 0.1984\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0527 - mae: 0.1921\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0507 - mae: 0.1861\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0492 - mae: 0.1814\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0480 - mae: 0.1771\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0471 - mae: 0.1745\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0463 - mae: 0.1720\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0458 - mae: 0.1706\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0451 - mae: 0.1688\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0445 - mae: 0.1675\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0438 - mae: 0.1659\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0433 - mae: 0.1647\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1634\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.1624\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 0.1611\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0406 - mae: 0.1599\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0400 - mae: 0.1587\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0393 - mae: 0.1575\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0387 - mae: 0.1566\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0381 - mae: 0.1557\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0375 - mae: 0.1546\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0369 - mae: 0.1532\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1518\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1504\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0351 - mae: 0.1490\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1477\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1460\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1448\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0328 - mae: 0.1436\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0323 - mae: 0.1426\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0317 - mae: 0.1414\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0312 - mae: 0.1404\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0307 - mae: 0.1392\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 927us/step - loss: 0.0302 - mae: 0.1381\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0297 - mae: 0.1370\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1359\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1349\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.1338\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0278 - mae: 0.1326\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0274 - mae: 0.1316\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0268 - mae: 0.1305\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0264 - mae: 0.1293\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1282\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0254 - mae: 0.1268\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1255\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1240\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 575us/step - loss: 0.0238 - mae: 0.1224\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0232 - mae: 0.1207\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.1189\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.1174\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0213 - mae: 0.1156\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0206 - mae: 0.1133\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0199 - mae: 0.1112\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0193 - mae: 0.1093\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.1082\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1066\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1050\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.1035\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.1022\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.1008\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0996\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0983\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0972\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 83us/step - loss: 0.0151 - mae: 0.0959\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0147 - mae: 0.0947\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0144 - mae: 0.0933\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0922\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0913\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0903\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0131 - mae: 0.0894\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0128 - mae: 0.0886\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0126 - mae: 0.0878\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0868\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0120 - mae: 0.0859\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0118 - mae: 0.0851\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0844\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0112 - mae: 0.0834\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0825\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0108 - mae: 0.0816\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0106 - mae: 0.0810\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0104 - mae: 0.0804\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0102 - mae: 0.0797\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0100 - mae: 0.0791\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0781\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0774\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0767\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0761\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0755\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0748\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0743\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0087 - mae: 0.0740\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0738\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0085 - mae: 0.0734\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0728\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0082 - mae: 0.0722\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0081 - mae: 0.0719\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0716\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0712\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0710\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0705\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0703\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0700\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0696\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0692\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0687\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 550us/step - loss: 0.0071 - mae: 0.0684\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0070 - mae: 0.0680\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0069 - mae: 0.0677\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0068 - mae: 0.0673\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0067 - mae: 0.0669\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0667\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0664\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0663\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0659\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0064 - mae: 0.0655\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0652\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0063 - mae: 0.0649\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0645\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0062 - mae: 0.0644\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0641\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0639\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0636\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 556us/step - loss: 0.0059 - mae: 0.0636\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0059 - mae: 0.0633\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0058 - mae: 0.0630\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0058 - mae: 0.0627\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0624\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0057 - mae: 0.0621\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0056 - mae: 0.0619\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0616\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0614\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0612\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0609\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0608\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0605\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0604\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0602\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0599\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0597\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0594\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0592\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0590\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0588\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0587\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0585\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0584\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0583\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0582\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0580\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0578\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0575\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0572\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0570\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0568\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0566\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0564\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0562\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0561\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0559\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0558\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0556\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0555\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0553\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0550\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0549\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0546\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0544\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0541\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0538\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0536\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0535\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0534\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0532\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0529\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0527\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0525\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0523\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0522\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0522\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0522\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0520\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0518\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0517\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0516\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0516\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0039 - mae: 0.0514\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0039 - mae: 0.0512\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0510\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0507\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0507\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0507\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0038 - mae: 0.0505\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0038 - mae: 0.0502\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0037 - mae: 0.0500\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0037 - mae: 0.0498\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0497\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0495\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0494\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0494\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0036 - mae: 0.0493\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0036 - mae: 0.0491\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0036 - mae: 0.0490\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0036 - mae: 0.0489\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0036 - mae: 0.0487\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0486\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0485\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0484\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0484\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0482\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0482\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0034 - mae: 0.0480\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0034 - mae: 0.0478\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0034 - mae: 0.0479\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0034 - mae: 0.0477\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0476\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0475\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0474\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0472\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0471\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0033 - mae: 0.0471\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0033 - mae: 0.0471\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0033 - mae: 0.0470\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0033 - mae: 0.0468\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0467\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0466\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0464\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0463\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0032 - mae: 0.0463\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0032 - mae: 0.0465\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0465\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0463\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0459\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0457\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0455\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0454\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0456\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0454\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0030 - mae: 0.0454\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0030 - mae: 0.0452\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0030 - mae: 0.0451\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0030 - mae: 0.0450\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0030 - mae: 0.0449\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0448\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0446\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0445\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0444\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0444\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0443\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 705us/step - loss: 0.0029 - mae: 0.0442\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0441\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0028 - mae: 0.0441\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0028 - mae: 0.0441\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0028 - mae: 0.0440\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0439\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0438\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0437\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0436\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0028 - mae: 0.0435\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0434\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0027 - mae: 0.0434\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0027 - mae: 0.0433\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0027 - mae: 0.0431\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0027 - mae: 0.0432\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0027 - mae: 0.0429\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0429\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0429\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 587us/step - loss: 0.0027 - mae: 0.0428\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0427\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0026 - mae: 0.0427\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0026 - mae: 0.0426\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0026 - mae: 0.0426\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0026 - mae: 0.0425\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0424\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0425\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0422\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0026 - mae: 0.0422\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0420\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0025 - mae: 0.0420\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0025 - mae: 0.0418\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0025 - mae: 0.0418\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0418\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0417\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0416\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0415\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0025 - mae: 0.0414\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0414\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0413\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0412\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0024 - mae: 0.0411\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0024 - mae: 0.0410\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0410\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0409\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0024 - mae: 0.0409\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0024 - mae: 0.0408\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0024 - mae: 0.0408\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0024 - mae: 0.0408\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0024 - mae: 0.0407\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0406\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0404\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0403\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0403\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0403\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0403\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0401\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0023 - mae: 0.0400\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0398\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0023 - mae: 0.0399\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0023 - mae: 0.0398\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0023 - mae: 0.0396\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0396\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 567us/step - loss: 0.0022 - mae: 0.0396\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0022 - mae: 0.0395\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0022 - mae: 0.0395\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0022 - mae: 0.0393\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0022 - mae: 0.0391\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0022 - mae: 0.0389\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0388\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0386\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0385\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0021 - mae: 0.0384\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0021 - mae: 0.0383\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0021 - mae: 0.0382\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0021 - mae: 0.0381\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0021 - mae: 0.0380\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0021 - mae: 0.0379\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0378\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0376\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0376\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0021 - mae: 0.0376\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0020 - mae: 0.0375\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0020 - mae: 0.0373\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0372\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0020 - mae: 0.0372\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0020 - mae: 0.0371\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0370\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0368\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0369\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0367\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0366\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0365\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0365\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0363\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0362\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0362\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0361\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0360\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0359\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0358\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0357\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0019 - mae: 0.0356\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0019 - mae: 0.0355\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0355\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0018 - mae: 0.0354\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0018 - mae: 0.0353\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0353\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0352\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0352\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0350\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0349\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0348\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0347\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0018 - mae: 0.0346\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0018 - mae: 0.0345\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0017 - mae: 0.0345\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0017 - mae: 0.0343\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0017 - mae: 0.0343\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0343\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0342\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0341\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0340\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0017 - mae: 0.0339\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0017 - mae: 0.0339\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - mae: 0.0338\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0017 - mae: 0.0337\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0017 - mae: 0.0336\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0336\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0335\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0334\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0334\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0016 - mae: 0.0334\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0016 - mae: 0.0334\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0016 - mae: 0.0332\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0332\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0331\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0329\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0016 - mae: 0.0329\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0016 - mae: 0.0328\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0016 - mae: 0.0327\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0016 - mae: 0.0326\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0326\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0326\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0327\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0324\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.0016 - mae: 0.0323\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0324\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0322\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0321\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0321\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0321\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0320\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0319\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0015 - mae: 0.0318\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0317\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0318\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0316\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0015 - mae: 0.0315\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0015 - mae: 0.0315\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0015 - mae: 0.0314\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0015 - mae: 0.0314\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0313\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0312\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0312\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0313\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0310\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0310\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0310\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0308\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0307\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0307\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0306\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0305\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0305\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0305\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0304\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0302\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0302\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0302 \n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0301\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0301\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0300\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0301\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0302\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - mae: 0.0299\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - mae: 0.0298 \n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - mae: 0.0297\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0297\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - mae: 0.0298\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - mae: 0.0296\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.0013 - mae: 0.0295\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0295\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0294\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - mae: 0.0293\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - mae: 0.0294\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0013 - mae: 0.0293\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0292\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0292\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0291\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0290\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0290\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0289\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0288\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - mae: 0.0288\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 915us/step - loss: 0.0013 - mae: 0.0288\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0287\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0286\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0286 \n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0286\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0284\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0284\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0283\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0283\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0282\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0281\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0281\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0280\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0280 \n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 310us/step - loss: 0.0012 - mae: 0.0279\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0280\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0277\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0277\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0276\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0276\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0275\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0275 \n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0278 \n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0012 - mae: 0.0276\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0054 - mae: 0.0647\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0155 - mae: 0.0913\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = 'mae')\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=500)\n",
    "\n",
    "loss, mae = model.evaluate(X_test, Y_test)\n",
    "loss_n,mae_n = model.evaluate(X_test_n,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0039 - mae: 0.0522\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0107 - mae: 0.0826\n"
     ]
    }
   ],
   "source": [
    "history_n = model.fit(X_train_n, Y_train, epochs = 500, verbose=0)\n",
    "loss_n2, mae_n2 = model.evaluate(X_test,Y_test)\n",
    "loss_n1,mae_n1 = model.evaluate(X_test_n,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04459765  0.49064693 -0.18506545  0.05879327  0.89807665  0.18715651\n",
      "  0.19493283 -0.03101794  0.11972971 -0.22555986  0.1790351  -0.6253892\n",
      "  0.26756668  0.09131245 -0.5689175  -0.19244604 -0.0684584 ]\n"
     ]
    }
   ],
   "source": [
    "latent_space_weights = model.layers[1].get_weights()[0]\n",
    "latent_space_bias  = model.layers[1].get_weights()[1]\n",
    "weights = np.append(latent_space_bias[0],latent_space_weights[:,0])\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 16)\n",
      "(80,)\n",
      "[[ 0.43538496 -0.20142959 -0.          0.11687309 -0.42831197 -0.09776349\n",
      "  -0.08490457  0.64178133]\n",
      " [-0.20846498 -0.02863076  0.4282363  -0.10858114 -0.         -0.38376194\n",
      "   0.4639828  -0.03861752]\n",
      " [ 0.05784106  0.11596218 -0.065527    0.06580551 -0.         -0.17863694\n",
      "   0.01613957 -0.04658325]\n",
      " [ 0.8120627  -0.16459064 -0.40397486 -0.01469484  0.15509921  0.02522924\n",
      "   0.5236064   0.12453867]\n",
      " [ 0.15321311 -0.43890136  0.14816076 -0.54795796  0.21802104 -0.25820675\n",
      "   0.2034209   0.4714536 ]\n",
      " [ 0.12809889  0.06765994  0.22381578 -0.03421715 -0.50586    -0.13863792\n",
      "   0.          0.36529627]\n",
      " [-0.         -0.16018783  0.11433794 -0.03076503 -0.55388343 -0.00184407\n",
      "  -0.16563202 -0.43398154]\n",
      " [ 0.          0.07151664  0.26003465 -0.          0.         -0.07880964\n",
      "  -0.          0.20520988]\n",
      " [-0.2036527  -0.10503339  0.17807472  0.6130325  -0.18140803 -0.01091815\n",
      "   0.6059138   0.15954205]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [-0.51671016 -0.         -0.42180353 -0.10887343  0.09728733 -0.53526527\n",
      "  -0.14922352 -0.        ]\n",
      " [ 0.19736204  0.15173484  0.          0.23555014 -0.22332588  0.19661058\n",
      "   0.09069506 -0.20562337]\n",
      " [ 0.         -0.         -0.         -0.          0.5019686   0.\n",
      "   0.          0.19846962]\n",
      " [-0.49428624 -0.46797714  0.4714193  -0.0436768  -0.24465573  0.43059304\n",
      "  -0.23898074 -0.04229959]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [-0.08999654 -0.05649934  0.4958198   0.20586063  0.35125175  0.\n",
      "  -0.          0.08003572]] [-0.00068717 -0.13761598 -0.06098771 -0.03020978 -0.01354027 -0.10965595\n",
      " -0.07189524  0.04273644]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "hidden_layaers = keras.backend.function(\n",
    "[model.layers[0].input],\n",
    "[model.layers[0].output,] \n",
    ")\n",
    "\n",
    "a = np.array(hidden_layaers([X_train])).reshape(80,16)\n",
    "X_new = a[0,:]\n",
    "aa = X_new[0]\n",
    "print(a.shape)\n",
    "\n",
    "get_8th_layer_output = K.function([model.layers[0].input], [model.layers[1].output])\n",
    "hidden_layer_output = get_8th_layer_output([X_train])[0]\n",
    "\n",
    "Y_new = hidden_layer_output[:,0]\n",
    "print(Y_new.shape)\n",
    "\n",
    "le = Lasso(alpha=0.001,max_iter=5000)\n",
    "le.fit(a,hidden_layer_output)\n",
    "print(le.coef_.T,le.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class Lasso_6:\n",
    "\n",
    "    def __init__(self, alpha, epoch = 50, weights = np.zeros(17,)):\n",
    "        self.alpha = alpha  # tuning parameter(penalty term)  \n",
    "        self.epoch =  epoch  # No. of iterations (default = 1000)\n",
    "        self.coef = None    # Weights or Co-eficients\n",
    "        self.bias = None    # Bias or intercept\n",
    "        self.weights = weights\n",
    "\n",
    "    def soft_threshold(self,rho,lamda):\n",
    "        if rho < - lamda:\n",
    "            return rho + lamda\n",
    "        elif rho > lamda:\n",
    "            return rho - lamda\n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "            X = np.column_stack((np.ones(len(X)), X))   # Training features\n",
    "            n = X.shape[0]\n",
    "            beta = copy.deepcopy(self.weights) # array of bias and weights\n",
    "            beta[0] = np.sum(y - np.dot(X[:, 1:], beta[1:])) / (X.shape[0])\n",
    "\n",
    "            for iteration in range(self.epoch):                                         \n",
    "                for j in range(1,17):                        \n",
    "                        beta[j] = 0.0                       \n",
    "                        error  = y - np.dot(X,beta)                                              \n",
    "                        rho = np.dot(X[:,j], error )                        \n",
    "                        lamda  = self.alpha*n\n",
    "\n",
    "                        beta[j] = self.soft_threshold(rho , lamda ) / ((X[:, j]**2).sum()+1e-20) \n",
    "                        \n",
    "                        beta[0] = np.sum(y - np.dot(X[:, 1:], beta[1:])) / (X.shape[0])\n",
    "            \n",
    "            self.coef = beta[1:]\n",
    "            self.bias = beta[0]                   \n",
    "                \n",
    "            return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43554944 -0.20135055  0.          0.11671109 -0.42840153 -0.09780651\n",
      "  -0.08502123  0.64175367]\n",
      " [-0.2083488  -0.02853689  0.42813179 -0.10883586  0.         -0.38382584\n",
      "   0.46376863 -0.0386603 ]\n",
      " [ 0.05772162  0.11584782 -0.06536835  0.06612629  0.         -0.17856258\n",
      "   0.01639658 -0.0465074 ]\n",
      " [ 0.81215638 -0.16454613 -0.40394092 -0.01477286  0.15508462  0.02521072\n",
      "   0.5235455   0.12451976]\n",
      " [ 0.15327752 -0.43881029  0.14816692 -0.54824674  0.21825691 -0.25826389\n",
      "   0.20323232  0.47137088]\n",
      " [ 0.12803431  0.06760647  0.22390231 -0.03409837 -0.50571948 -0.13859063\n",
      "   0.          0.36530596]\n",
      " [ 0.         -0.16009164  0.11432134 -0.03118246 -0.55347264 -0.00193125\n",
      "  -0.16594425 -0.43407351]\n",
      " [ 0.          0.07161628  0.2601192   0.          0.         -0.07886999\n",
      "   0.          0.20511676]\n",
      " [-0.20371957 -0.10516316  0.178067    0.61345643 -0.1817978  -0.01082665\n",
      "   0.60622936  0.1596635 ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [-0.51678169  0.         -0.42178699 -0.10925745  0.0976995  -0.53534609\n",
      "  -0.14950718  0.        ]\n",
      " [ 0.19746622  0.15189922  0.          0.23508465 -0.2229386   0.19651523\n",
      "   0.09034969 -0.20576781]\n",
      " [ 0.          0.          0.          0.          0.50167727  0.\n",
      "   0.          0.19859387]\n",
      " [-0.49446508 -0.46809652  0.47158441 -0.04344552 -0.24452442  0.43065333\n",
      "  -0.23877724 -0.04223712]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [-0.08999956 -0.05647865  0.49593922  0.20581996  0.3514635   0.\n",
      "   0.          0.07998922]] [-0.00079728 -0.13771197 -0.06107222 -0.02988036 -0.01376132 -0.1095868\n",
      " -0.07166874  0.0427902 ]\n"
     ]
    }
   ],
   "source": [
    "coeff = np.zeros((16,8))\n",
    "bias = np.zeros(8)\n",
    "\n",
    "#for loop over the neurons:\n",
    "for i in range (hidden_layer_output.shape[1]):\n",
    "    weights_l = np.append(latent_space_bias[i],latent_space_weights[:,i])\n",
    "    model_l = Lasso_6(alpha=0.001,epoch=1000,weights=weights_l)\n",
    "    model_l.fit(a,hidden_layer_output[:,i])\n",
    "    coeff[:,i]= model_l.coef\n",
    "    bias[i] = model_l.bias\n",
    "\n",
    "print(coeff,bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0298\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - mae: 0.0442\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0055 - mae: 0.0595\n"
     ]
    }
   ],
   "source": [
    "wla = [coeff,bias]\n",
    "model.layers[1].set_weights(wla)\n",
    "model.layers[1].trainable = False\n",
    "model.compile(optimizer='adam',loss='mse',metrics = 'mae')\n",
    "model.fit(X_train_n,Y_train)\n",
    "loss_n3,mae_n3 = model.evaluate(X_test,Y_test)\n",
    "loss_n4,mae_n4 = model.evaluate(X_test_n,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
    "raw_data = dataframe.values\n",
    "\n",
    "X_A = raw_data[:,:-1]\n",
    "Y_A = raw_data[:,-1]\n",
    "\n",
    "Xa_train,Xa_test,Ya_train,Ya_test = train_test_split(X_A,Y_A,test_size=0.2, random_state=21)\n",
    "\n",
    "min_val = tf.reduce_min(Xa_train)\n",
    "max_val = tf.reduce_max(Xa_train)\n",
    "\n",
    "Xa_train = (Xa_train - min_val) / (max_val - min_val)\n",
    "Xa_test = (Xa_test - min_val) / (max_val - min_val)\n",
    "\n",
    "Xa_train = tf.cast(Xa_train, tf.float32)\n",
    "Xa_test = tf.cast(Xa_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 337.\n",
      "Epoch 357: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "0.005325591\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "class AnomalyDetector(Model):\n",
    "    def __init__(self):\n",
    "        super(AnomalyDetector, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dense(20, activation=\"linear\",input_shape=(140,))]) \n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(32,activation=\"linear\"),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(140, activation=\"sigmoid\")])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "autoencoder = AnomalyDetector()\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
    "autoencoder.fit(Xa_train,Xa_train,validation_split=0.2,epochs=1000,batch_size=32,verbose=0,callbacks=[early_stop])\n",
    "\n",
    "re = autoencoder.predict(Xa_test)\n",
    "test_loss_a = tf.keras.losses.mae(re, Xa_test)\n",
    "print(np.mean(test_loss_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 970us/step\n",
      "0.0052813394\n"
     ]
    }
   ],
   "source": [
    "re_train = autoencoder.predict(Xa_train)\n",
    "test_loss_train = tf.keras.losses.mae(re_train, Xa_train)\n",
    "print(np.mean(test_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix_latent_to_decoder = autoencoder.decoder.layers[0].get_weights()[0]\n",
    "bias_matrix_latent_to_decoder = autoencoder.decoder.layers[0].get_weights()[1]\n",
    "print(weight_matrix_latent_to_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3998, 20)\n",
      "[[ 0.26744422  0.55891997  0.38070428 ...  0.23651758 -0.41600615\n",
      "   0.23978505]\n",
      " [ 0.35815355  0.19936179  0.14287336 ...  0.21026611 -0.43172306\n",
      "   0.25828904]\n",
      " [ 0.32474983  0.5666979   0.3416637  ...  0.21180683 -0.35946244\n",
      "   0.23734158]\n",
      " ...\n",
      " [ 0.34396482  0.2953583   0.18585521 ...  0.20511869 -0.3988299\n",
      "   0.26419836]\n",
      " [ 0.3650685   0.6176806   0.4258166  ...  0.11260696 -0.3955584\n",
      "   0.28022105]\n",
      " [ 0.2527079   0.37883827  0.3028735  ...  0.2638248  -0.3635211\n",
      "   0.2097286 ]]\n"
     ]
    }
   ],
   "source": [
    "xa_new = autoencoder.encoder(Xa_train)\n",
    "print(xa_new.shape)\n",
    "\n",
    "hidden_layaers_1a = keras.backend.function(\n",
    "[autoencoder.decoder.layers[0].input],    \n",
    "[autoencoder.decoder.layers[0].output,] \n",
    ")\n",
    "\n",
    "aa_1 = np.array(hidden_layaers_1a([xa_new])).reshape(3998,32)\n",
    "print(aa_1)\n",
    "Ya_new = aa_1[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Scikit learn lib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "0.005442526\n"
     ]
    }
   ],
   "source": [
    "la = Lasso(alpha=0.0001,max_iter=1000000)\n",
    "la.fit(xa_new,aa_1)\n",
    "w = la.coef_.T\n",
    "b = la.intercept_\n",
    "c_w = [w,b]\n",
    "\n",
    "autoencoder.decoder.layers[0].set_weights(c_w)\n",
    "\n",
    "#autoencoder.decoder.layers[0].trainable = False  \n",
    "\n",
    "#autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#autoencoder.fit(Xa_train,Xa_train,epochs=500,batch_size=32,verbose=0)\n",
    "re_a = autoencoder.predict(Xa_test)\n",
    "test_loss_aa = np.mean(tf.keras.losses.mae(re_a, Xa_test))\n",
    "print(test_loss_aa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix_latent_to_decoder_a = autoencoder.decoder.layers[0].get_weights()[0]\n",
    "bias_matrix_latent_to_decoder_a = autoencoder.decoder.layers[0].get_weights()[1]\n",
    "print(weight_matrix_latent_to_decoder_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_19620\\2530756618.py:8: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  la.fit(xa_new,aa_1)\n",
      "e:\\Lectures\\Arbeit\\Sensorics\\sens\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[[-4.13608286e-01  4.74992679e-01  3.26849465e-01  6.59126058e-01\n",
      "  -1.15751005e-01  1.05384152e-01 -5.07301807e-01  2.68677178e-02\n",
      "  -6.41414883e-02  1.61483247e-02 -2.13837680e-01 -3.64617935e-01\n",
      "   1.51440246e+00 -2.34530077e-01  6.29801341e-01 -5.65230877e-01\n",
      "  -1.42600333e-02  4.18037551e-01  1.02390708e+00  5.15905081e-01\n",
      "   2.35262344e-02 -2.26980277e-01  6.62595304e-01 -3.84207278e-01\n",
      "   3.14237837e-01  5.08798701e-02  1.17773345e-01  5.65703581e-01\n",
      "   8.79154086e-02  1.59074730e-01  2.15110871e-01 -7.34322832e-02]\n",
      " [ 1.09269654e-02 -2.06759851e-01 -3.89489403e-01  6.07725545e-01\n",
      "   3.65208818e-02  3.50526032e-01 -3.67623861e-01  3.56084531e-03\n",
      "  -1.49998441e-01 -4.06996244e-01 -5.67195134e-01 -4.62937307e-02\n",
      "   2.20087540e-01 -2.43006848e-02 -1.94472188e-01 -1.71583636e-02\n",
      "   4.93186142e-02  2.35930027e-01  6.19520312e-02  4.84158371e-01\n",
      "   4.93896527e-01 -1.97144242e-03 -7.34990439e-02 -1.10764924e-01\n",
      "  -2.34493232e-01 -2.17728576e-01  1.93371953e-02 -9.04654524e-02\n",
      "   3.22010922e-01 -3.39793768e-02  5.70624834e-02 -6.44536921e-02]\n",
      " [ 2.85512922e-01 -5.70798145e-01 -5.34735683e-02  1.32178336e-01\n",
      "   2.44032694e-01 -2.57827090e-01  3.83635366e-01 -5.77205330e-02\n",
      "  -5.25964490e-01  5.52131670e-01 -5.15603989e-01 -2.78065925e-01\n",
      "  -1.75072622e+00  4.71287085e-01  9.59998996e-02  4.02085154e-01\n",
      "  -7.73469802e-02  1.24230545e-01 -3.44712056e-01 -1.57481679e-01\n",
      "  -4.27511154e-01 -1.93986929e-01 -1.06515998e+00  2.20199948e-01\n",
      "  -2.70512975e-01  1.15487077e-01  2.99421294e-01 -4.86835183e-01\n",
      "  -3.88555728e-01  1.68895083e-01 -2.73529826e-01  3.78376782e-01]\n",
      " [-2.12180580e-03 -3.29062716e-01 -1.93497707e-01  1.58913389e-01\n",
      "   1.79408188e-01  3.68481947e-01 -6.67261044e-02  1.21256129e-02\n",
      "  -5.86699924e-01 -1.43952421e-01 -2.10715470e-02 -1.72360849e-02\n",
      "   2.56323273e-01 -9.95075390e-02  2.87399386e-01 -4.39152513e-01\n",
      "   9.66573405e-02  2.01405344e-01  3.10180842e-01  1.16607515e-02\n",
      "   4.00831003e-01 -5.40797233e-01 -9.31085260e-02  3.64090600e-03\n",
      "   2.05690402e-01  1.51224931e-02 -2.67402918e-01  1.81213762e-01\n",
      "   2.56985222e-02  1.75909554e-02 -1.47209102e-01 -7.88112554e-02]\n",
      " [-5.16264016e-02  3.82679992e-02 -3.35343074e-02  6.63339735e-02\n",
      "   9.07587634e-03 -2.66238867e-01 -2.48588071e-03  1.79882322e-01\n",
      "  -3.78609715e-01 -2.75107361e-01 -2.36056099e-01 -2.25709963e-01\n",
      "  -6.00344744e-02 -2.69137094e-01 -2.33722802e-01  5.29327932e-01\n",
      "  -1.07490771e-01  2.98133893e-01  4.65756377e-01  3.68735516e-01\n",
      "   2.16765084e-01 -5.67540566e-01 -1.27964336e-01  2.26083703e-02\n",
      "  -4.85584772e-01  2.39076875e-01  1.02479292e-01 -1.00011322e-01\n",
      "   8.40567150e-02 -1.57066835e-01  7.12351826e-02 -7.50302747e-01]\n",
      " [-3.35473072e-01 -9.51712252e-02 -1.58724300e-01 -1.29440910e-01\n",
      "   5.36635144e-02 -1.83812638e-01 -2.69731000e-02 -3.20848642e-01\n",
      "  -1.11534513e-01 -6.85982072e-02  2.96748063e-01 -1.84972426e-01\n",
      "  -2.78518580e-01  3.53280830e-01 -4.74781150e-01  3.31032290e-01\n",
      "  -3.32666960e-02  1.17708362e-02 -9.12672586e-02  2.41225316e-01\n",
      "   1.41922658e-01 -4.40354872e-02 -3.69901140e-01  1.25635483e-01\n",
      "  -4.36800967e-01 -1.82873099e-01  7.02386037e-03 -1.21485294e-01\n",
      "  -8.30529833e-03  1.11297532e-01  9.31044040e-02 -4.75056460e-01]\n",
      " [-6.85496827e-02 -1.65612650e-01  4.74920884e-01 -1.84629625e-02\n",
      "   1.94832823e-01  3.29824412e-01 -1.01226322e-01 -3.09630802e-01\n",
      "   1.33481286e-01  1.96300430e-01  2.83362462e-01  1.84187733e-01\n",
      "  -1.06884420e-01  4.92363235e-01  1.60488323e-01 -1.15954452e-02\n",
      "  -5.77426576e-02 -3.31112668e-01  2.13918170e-03  1.18828442e-01\n",
      "  -9.22900501e-02  5.61775593e-02 -3.72794729e-01 -5.63763846e-02\n",
      "  -1.76431245e-01 -1.92710921e-01  9.38793164e-02 -2.40722654e-01\n",
      "  -1.63384265e-01 -1.69013883e-01 -4.94857995e-03  1.22523797e-01]\n",
      " [-2.29803370e-02 -1.53489528e-01 -1.63337705e-01 -2.83083180e-01\n",
      "  -1.81833299e-01 -2.09927540e-01  1.52932579e-01 -4.33343241e-02\n",
      "   7.78981107e-01 -3.48661347e-01  1.41460111e-01 -1.82330905e-01\n",
      "   9.66061179e-01  3.67144594e-01 -5.39059136e-02 -5.29705510e-01\n",
      "  -1.72835272e-01 -6.17096319e-02 -3.12167982e-01 -9.17263918e-02\n",
      "  -8.93147356e-02  2.84423591e-01  4.35190549e-01  3.96168526e-01\n",
      "  -4.37426131e-02  4.67777011e-02  1.21355120e-01 -1.29162170e-01\n",
      "   1.81641593e-03  1.13496765e-01  6.20996410e-02  1.06771875e-01]\n",
      " [ 2.73579237e-02  9.99200563e-02  1.73576591e-02  1.70493760e-01\n",
      "  -1.10528891e-01 -2.87992382e-01 -5.42360687e-01  1.61836913e-01\n",
      "  -1.44827923e-01 -3.84485427e-01  6.53211127e-01  5.43551490e-01\n",
      "   1.00775199e+00  4.93595753e-01  6.58502655e-01 -2.25906028e-01\n",
      "  -4.74294602e-01  3.23350197e-01 -1.63476717e-01  1.96893536e-01\n",
      "   6.39512275e-02 -2.04807504e-01  4.66059815e-01  3.25584326e-01\n",
      "   9.42336121e-03  1.17162064e-01  4.15190015e-01  2.20607600e-01\n",
      "  -2.97560042e-01  5.35993651e-01  1.42682559e-01 -1.79016889e-01]\n",
      " [-3.73812488e-02  6.53060962e-02  3.35259059e-01  2.63628172e-01\n",
      "   4.43426039e-01 -1.63999087e-01  1.26117658e-01  3.33746918e-03\n",
      "  -8.77145153e-02 -3.86101337e-02 -3.39037614e-01  5.55246231e-01\n",
      "  -8.98361459e-02  1.88434318e-01  1.44965634e-01  4.01644854e-01\n",
      "   4.07149583e-01  2.53848117e-01  1.14229433e-01  9.56450217e-02\n",
      "   2.03399312e-01  2.16737742e-01  5.58475542e-02  2.88975554e-01\n",
      "   4.59546694e-01 -5.94604549e-02  2.24134407e-01 -2.58427460e-01\n",
      "  -4.03043104e-02  4.95205106e-02 -2.67287113e-01 -1.75157651e-02]\n",
      " [ 3.58749702e-01  8.38154947e-02 -4.87174323e-01 -1.56187739e-01\n",
      "  -1.11954396e-01  3.48060604e-01 -2.19628876e-01  3.96243378e-01\n",
      "   1.85746929e-01  5.30751502e-01  2.33633909e-01 -1.01828474e-01\n",
      "   2.62866194e-01 -1.48558435e-01  4.69950374e-01 -7.59410834e-02\n",
      "  -1.88661776e-01  7.07722500e-02 -5.56855733e-01 -6.31177737e-03\n",
      "  -1.84673020e-01 -2.77620976e-02  6.49337250e-02 -1.01104492e-01\n",
      "   1.04201307e-01 -8.31740320e-02  6.46868462e-01 -5.49038809e-01\n",
      "   1.41322097e-01 -5.26755909e-01 -5.07592935e-02  2.59096074e-01]\n",
      " [ 4.97699371e-01  2.05485678e-01 -1.25970399e-01  1.65575819e-01\n",
      "  -1.56492684e-01  2.08813652e-01 -9.05126164e-02 -7.86202706e-02\n",
      "   1.20774377e-01 -4.82809341e-01 -1.01577921e-01 -1.54800196e-01\n",
      "   1.08230784e-02  4.76544183e-01 -3.65429008e-02 -1.43452885e-01\n",
      "   4.27894331e-01 -4.77059814e-01 -1.14557216e-01  5.54967443e-02\n",
      "  -1.32038991e-02 -4.33364027e-03  1.28212804e-01 -2.44200149e-01\n",
      "   3.28643007e-02  1.29739137e-01 -2.47791837e-02 -4.53180775e-01\n",
      "  -7.69745405e-02  8.55071205e-02 -2.99907629e-01 -4.46362991e-02]\n",
      " [-2.68398850e-01 -3.79194516e-01  2.32878331e-01 -2.73582534e-01\n",
      "  -1.16708388e-01  3.05586036e-01  1.32145462e-01  7.14731874e-02\n",
      "   7.72636495e-03 -1.78114083e-01  5.01803231e-01 -2.19592767e-01\n",
      "  -1.27621639e+00 -1.26651524e-01  2.61665414e-03  7.76238799e-01\n",
      "   3.55080742e-01 -1.00556571e-02 -2.90952505e-01 -6.87790940e-02\n",
      "   5.74770214e-02  2.72279029e-01 -4.01514117e-01  8.40946494e-02\n",
      "  -4.51011506e-01  3.76733023e-02 -4.85872374e-01 -5.13494431e-01\n",
      "  -2.03391190e-01 -6.39179437e-02 -2.01351574e-01  1.53186558e-01]\n",
      " [ 7.89717148e-02  4.70609569e-03 -1.27236316e-01 -5.45319140e-03\n",
      "   7.44747160e-02  1.57692110e-01  8.31265887e-03 -6.70498825e-03\n",
      "   3.15287588e-01 -3.23979913e-01 -1.50683465e-01 -1.12581194e-01\n",
      "  -1.68605138e-01  2.28890317e-01 -1.05979108e-01  4.98645708e-03\n",
      "   3.34196807e-01 -1.49567081e-01 -2.12835825e-01  8.40338601e-02\n",
      "   5.42465070e-03  3.29316820e-01  3.03828881e-02 -5.43487833e-02\n",
      "  -1.37616938e-02 -1.92251181e-01 -1.22983790e-01 -4.16477096e-01\n",
      "  -1.07633914e-01  7.14671455e-02 -1.54389016e-01  1.91243776e-01]\n",
      " [-9.07507749e-02 -8.43059089e-02 -3.08539906e-01 -2.92650586e-01\n",
      "  -8.81961048e-02 -7.39469192e-02 -6.80011886e-02 -1.70112380e-01\n",
      "  -1.24410679e-01  1.47986874e-01  1.48479207e-01 -2.92612469e-01\n",
      "  -2.40998106e-01  1.00613489e-01 -3.20515779e-01  5.65701874e-02\n",
      "  -1.89887294e-01  3.60955851e-03 -2.12799614e-01 -6.00958501e-02\n",
      "   7.23137234e-02 -4.71223631e-02 -4.57852221e-02 -1.71992043e-02\n",
      "  -1.06273702e-01 -1.71209085e-01 -8.78512819e-02 -7.46281427e-02\n",
      "   2.13185156e-01 -2.70024314e-02  5.87757854e-02  6.47044075e-02]\n",
      " [ 3.85232784e-02  1.36848060e-01  3.54871471e-01  2.19521279e-01\n",
      "  -1.59600222e-01 -3.61237945e-02  2.94733113e-02  6.58287161e-02\n",
      "   3.35524124e-01 -2.26671044e-01 -1.34021935e-01  1.46748078e-01\n",
      "   4.60343033e-01 -2.26730856e-01 -7.60353495e-02 -5.57855142e-02\n",
      "  -7.27711946e-02 -3.70990773e-02  1.91200444e-01 -9.95534937e-02\n",
      "  -9.28536657e-02  2.59171732e-02  2.17570642e-01 -2.15996368e-02\n",
      "  -3.30947835e-01  2.68610177e-01 -1.68592630e-02  1.68058292e-01\n",
      "   8.07484611e-02 -5.69705547e-02  2.97307131e-02 -1.77252312e-01]\n",
      " [ 1.85304727e-01  8.20398829e-02 -4.75726909e-02 -1.56116827e-01\n",
      "   2.06529168e-01 -3.69833914e-02 -4.19099706e-01  8.87619777e-02\n",
      "  -3.20976048e-01 -6.47632257e-01 -7.82487976e-01 -3.35511076e-01\n",
      "  -2.15256904e-02 -1.52528629e-01 -3.63305965e-01 -3.12370095e-01\n",
      "  -4.73727974e-01  1.78521098e-01  4.77245213e-01 -4.67642718e-02\n",
      "   1.09029329e-01 -5.44808510e-01  4.41286073e-01 -5.04059416e-01\n",
      "  -5.00835881e-01 -3.24900543e-01 -7.34546138e-01 -3.07647818e-02\n",
      "   1.29758524e-01  1.97040261e-01 -2.21215353e-04  3.81978947e-01]\n",
      " [-9.98080754e-03  1.02115930e-01  1.77206528e-01  9.30096839e-02\n",
      "   2.78559901e-01 -7.52915414e-02  1.79376162e-01  6.21825985e-02\n",
      "   7.32277434e-02  1.62179607e-01 -3.98376248e-01  1.71735293e-01\n",
      "  -1.41303449e-01 -2.85687674e-01 -2.22582463e-01  1.67106799e-01\n",
      "   8.56896248e-02  2.45016608e-01  3.78768948e-02 -2.91491836e-01\n",
      "  -7.86815479e-02 -1.10093217e-02 -4.07924750e-02  2.14854409e-02\n",
      "  -2.19168972e-01 -2.65649130e-02  1.88216729e-02 -1.81627532e-01\n",
      "   1.40645677e-01 -1.68496344e-01 -2.36096960e-01 -3.78555355e-02]\n",
      " [ 1.27696383e-01 -9.40962552e-02  5.10339269e-01  2.79488725e-01\n",
      "  -8.94109054e-02  4.25885844e-01 -1.12770153e-01 -8.39487971e-03\n",
      "  -4.61550650e-02 -2.40203165e-01  1.79622416e-01  2.28346852e-01\n",
      "   4.66091461e-01  6.43422026e-02  4.81046123e-01 -1.92319246e-01\n",
      "   9.90076943e-02 -2.81868658e-01  4.31901052e-01  1.93245453e-01\n",
      "   1.37030788e-01 -2.32308987e-01  1.70672325e-02 -9.70393416e-02\n",
      "   7.56973772e-02  2.90225738e-01 -3.62494233e-02  1.30100441e-01\n",
      "  -1.07412031e-01 -1.56464960e-01 -2.50808191e-03 -1.34252747e-01]\n",
      " [-3.36233527e-02 -2.64259718e-01 -7.97300688e-02 -8.26963493e-02\n",
      "  -4.65314669e-02  2.75236770e-01 -2.92883759e-01 -2.39041819e-01\n",
      "  -3.13144980e-01 -3.91413879e-01  2.23207658e-01 -1.98542818e-01\n",
      "   5.01717712e-01  4.70714542e-01  1.05816623e-01 -1.10399452e-01\n",
      "  -4.06557355e-02 -1.99133600e-01  3.59530931e-01  5.85149320e-01\n",
      "   5.61409481e-01 -3.70771730e-01  6.63608035e-02  3.65816057e-04\n",
      "   2.07208390e-01 -6.88511803e-02 -4.91791014e-02 -1.00474438e-01\n",
      "   1.46612139e-01 -1.37361932e-01  1.41892056e-01 -2.37512068e-01]]\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "0.0052795946\n",
      "0.0001:[[-4.39555758e-01  1.06345538e-01  8.47428678e-02  3.05109307e-01\n",
      "  -4.88264717e-02 -0.00000000e+00 -2.17671645e-01  0.00000000e+00\n",
      "   1.24883527e-01 -0.00000000e+00  0.00000000e+00 -4.87781043e-01\n",
      "   3.53146462e-01 -2.43566409e-01  2.54946465e-02 -0.00000000e+00\n",
      "   0.00000000e+00  8.20242482e-02  3.39881596e-01  4.06965420e-01\n",
      "  -3.81191532e-02  1.61433210e-01  5.26572290e-01 -2.44876208e-01\n",
      "   0.00000000e+00 -0.00000000e+00  2.87430626e-02  1.68116588e-01\n",
      "  -0.00000000e+00  0.00000000e+00  1.30698535e-01 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00  6.39801316e-01\n",
      "   1.40325706e-01  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -5.53630418e-01 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  8.05425290e-02\n",
      "   1.40081434e-01  0.00000000e+00 -4.77301548e-01 -0.00000000e+00\n",
      "   0.00000000e+00 -1.54081368e-01  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -8.38020339e-03  0.00000000e+00]\n",
      " [ 1.50803713e-01 -4.54461055e-01 -7.66556301e-02  0.00000000e+00\n",
      "   0.00000000e+00 -3.52954327e-01  1.48050654e-01 -1.33280040e-01\n",
      "  -2.81438031e-01  2.83538567e-02 -0.00000000e+00 -0.00000000e+00\n",
      "  -7.34572592e-01  7.39072604e-01  0.00000000e+00  0.00000000e+00\n",
      "  -2.37037506e-02  0.00000000e+00 -2.07751974e-01 -0.00000000e+00\n",
      "  -2.74315696e-01 -2.09437420e-01 -6.91522287e-01  2.15814345e-01\n",
      "  -4.84348057e-02  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  -1.76112490e-01  4.02013502e-02 -0.00000000e+00  0.00000000e+00]\n",
      " [-0.00000000e+00 -5.03636942e-01 -6.25272101e-03 -0.00000000e+00\n",
      "   9.38179916e-02  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  -5.43439962e-01 -1.12882551e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -2.46145242e-01 -2.67066056e-01 -0.00000000e+00 -6.62831401e-02\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.19561193e-02\n",
      "   3.83872605e-01 -2.39732955e-01 -2.89037768e-02  0.00000000e+00\n",
      "   8.54099484e-02  5.44514165e-02 -3.50884477e-01  2.02815357e-01\n",
      "   2.41195013e-02 -0.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -9.52532859e-02 -0.00000000e+00  6.30845750e-02\n",
      "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  -3.81744161e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00  4.79646077e-01\n",
      "   0.00000000e+00  1.41127040e-01  1.38423828e-01  2.17685221e-01\n",
      "   0.00000000e+00 -5.31731704e-01 -1.17001115e-01  0.00000000e+00\n",
      "  -2.80506973e-01  9.48244374e-02  0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -9.68986448e-02 -0.00000000e+00 -3.64900766e-01]\n",
      " [-2.33494311e-01  1.78504876e-02  2.07181123e-01  0.00000000e+00\n",
      "   0.00000000e+00 -5.20583372e-01  0.00000000e+00 -4.97003456e-01\n",
      "   0.00000000e+00  4.28951582e-02  2.71027818e-01  7.29302606e-02\n",
      "   0.00000000e+00  6.49553480e-01 -0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -1.95108088e-01  0.00000000e+00\n",
      "  -0.00000000e+00  1.20037852e-03 -0.00000000e+00  1.53054067e-01\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  -3.16972056e-02  2.33619488e-01  5.99227069e-03 -2.44566392e-01]\n",
      " [-0.00000000e+00 -1.45505009e-01  3.45293121e-01  1.10840688e-01\n",
      "   1.06597677e-01  4.25946574e-01 -3.65659298e-01 -2.21232865e-01\n",
      "  -0.00000000e+00 -1.11789559e-01  0.00000000e+00  8.91125467e-02\n",
      "   0.00000000e+00  3.33700694e-01  1.18706264e-01  0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00  2.27614072e-01  4.56145025e-01\n",
      "   1.99149849e-01 -0.00000000e+00 -0.00000000e+00 -8.85495215e-02\n",
      "  -3.81515414e-01 -0.00000000e+00  1.84329168e-01 -3.59131334e-01\n",
      "   0.00000000e+00 -1.17898839e-01 -0.00000000e+00 -5.83467955e-02]\n",
      " [-0.00000000e+00 -4.33424782e-03  0.00000000e+00 -0.00000000e+00\n",
      "  -3.27576338e-01 -2.90856791e-02  0.00000000e+00 -0.00000000e+00\n",
      "   2.31540369e-01 -0.00000000e+00  1.31128947e-01 -0.00000000e+00\n",
      "   1.27076713e+00  1.12012466e-01  0.00000000e+00 -4.75787621e-01\n",
      "  -1.95309987e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  2.76188913e-02  4.22099292e-01\n",
      "   0.00000000e+00  6.92768687e-02  1.66487451e-02  0.00000000e+00\n",
      "  -0.00000000e+00  1.52894435e-02  6.94865565e-02 -0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 -8.57051451e-03\n",
      "  -0.00000000e+00 -6.09938182e-01 -3.04777405e-01  2.69986024e-01\n",
      "  -2.53181149e-01  0.00000000e+00  3.37794456e-01  1.32513918e-01\n",
      "   2.10469467e-02  0.00000000e+00  2.53826205e-01  2.14817635e-01\n",
      "  -8.21250529e-01  1.28900092e-01 -3.12381137e-01 -0.00000000e+00\n",
      "  -2.49037424e-02 -0.00000000e+00  0.00000000e+00  2.38870018e-01\n",
      "  -2.33421478e-01  4.69429662e-02  4.90186084e-01  0.00000000e+00\n",
      "  -3.57745645e-01  5.52554508e-01  2.13430458e-01 -0.00000000e+00]\n",
      " [-1.16059866e-01  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "   3.11361840e-01 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.10035322e-01\n",
      "   0.00000000e+00  1.18673241e-01 -1.12023048e-01  4.17024373e-01\n",
      "   2.41032447e-01 -8.95455135e-03 -1.02181471e-01  1.02865331e-01\n",
      "   8.16377660e-02  2.92756742e-01 -0.00000000e+00  1.66725994e-01\n",
      "   4.00788862e-01 -3.17684828e-01  1.05762297e-02 -4.21299062e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00]\n",
      " [ 3.26385914e-01  0.00000000e+00 -5.57973057e-02 -1.36507599e-01\n",
      "  -2.26377227e-01  2.22742184e-01 -2.73851763e-01  2.98463360e-01\n",
      "   1.46355754e-01  2.24493352e-01  4.54356486e-01  2.12856505e-01\n",
      "   5.77365068e-01  0.00000000e+00  3.77850265e-01 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.86170880e-01  6.62236949e-02\n",
      "  -0.00000000e+00  0.00000000e+00  2.01857901e-01 -2.75595764e-02\n",
      "   1.18687526e-01 -1.15463231e-02  3.84323551e-01 -3.08961570e-01\n",
      "   1.66680863e-01 -5.80635583e-01  0.00000000e+00  8.29104106e-02]\n",
      " [ 4.12923466e-01  1.82863535e-01  0.00000000e+00  8.77237577e-02\n",
      "  -1.90894515e-01  8.71292892e-02 -1.52660989e-01 -1.15811674e-02\n",
      "   3.97577379e-02 -4.58933397e-01 -8.15401822e-02 -1.70537837e-01\n",
      "   2.10746883e-01  2.65587735e-01 -1.17509333e-01 -7.65472796e-02\n",
      "   2.57475828e-01 -5.20793505e-01  3.77688107e-02  9.16541413e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.62673945e-01\n",
      "  -0.00000000e+00 -0.00000000e+00 -5.08021744e-02 -1.58067705e-01\n",
      "  -0.00000000e+00  8.69257555e-02 -4.20444814e-02 -3.81705931e-02]\n",
      " [-2.93038505e-01 -0.00000000e+00  2.17330120e-01 -1.80586765e-01\n",
      "  -3.94275128e-01  2.00859124e-01 -2.17274540e-01  1.22503414e-02\n",
      "   1.18384315e-01 -2.70057923e-01  7.08558269e-01 -0.00000000e+00\n",
      "   0.00000000e+00 -1.52371869e-03  3.68373970e-01  1.01514950e-01\n",
      "   2.28988087e-01  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00  9.44554092e-02  0.00000000e+00 -3.86079978e-02\n",
      "  -0.00000000e+00  0.00000000e+00 -6.29739048e-01  1.04192643e-01\n",
      "  -3.61074233e-02 -0.00000000e+00  1.10313376e-01 -0.00000000e+00]\n",
      " [ 9.88793683e-02 -0.00000000e+00 -5.00883166e-01 -0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   6.19711391e-02  0.00000000e+00 -2.86140446e-01 -2.79159871e-01\n",
      "  -6.96840134e-01  0.00000000e+00 -2.42459584e-01  6.02672953e-02\n",
      "   9.46692448e-02 -1.06426613e-01 -4.54233812e-01 -0.00000000e+00\n",
      "   0.00000000e+00  4.17243632e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -9.02677468e-02 -0.00000000e+00 -7.51998768e-01\n",
      "  -0.00000000e+00  0.00000000e+00 -2.02128609e-01  2.95417411e-01]\n",
      " [ 0.00000000e+00 -1.56805279e-01 -0.00000000e+00 -2.64576395e-01\n",
      "   0.00000000e+00  0.00000000e+00  3.57376922e-02 -8.83336749e-02\n",
      "   0.00000000e+00  8.34916825e-02  0.00000000e+00 -2.85019166e-01\n",
      "  -6.31758940e-01  3.90221487e-02 -3.15431331e-01  4.38946455e-01\n",
      "   0.00000000e+00 -0.00000000e+00 -2.51584033e-01 -2.97125345e-03\n",
      "   0.00000000e+00  0.00000000e+00 -7.51528547e-02 -0.00000000e+00\n",
      "  -3.85440342e-01 -3.11724067e-02 -9.99519390e-02 -9.75012460e-02\n",
      "  -3.92826882e-02  7.16644469e-02  0.00000000e+00  5.10380639e-02]\n",
      " [ 4.75231320e-02 -0.00000000e+00  1.74753229e-01 -0.00000000e+00\n",
      "  -7.94516593e-02 -7.44542871e-02  1.77837387e-01  0.00000000e+00\n",
      "   7.69525635e-01 -3.16801483e-01  0.00000000e+00  9.00021668e-02\n",
      "   7.58991037e-02  0.00000000e+00 -1.12637313e-01 -0.00000000e+00\n",
      "  -0.00000000e+00 -1.90069204e-01 -2.72964106e-01 -2.13888127e-01\n",
      "  -2.99976279e-01  2.86963322e-01  4.69383128e-01  3.76019343e-04\n",
      "  -3.34629650e-01  2.23887962e-01 -0.00000000e+00  7.46054956e-02\n",
      "  -1.10379826e-02  0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [ 1.31375547e-01  2.60576249e-02  0.00000000e+00 -1.15143552e-01\n",
      "   1.46287221e-01 -0.00000000e+00 -2.74564938e-01  0.00000000e+00\n",
      "  -3.02720798e-01 -5.11480830e-01 -3.54855801e-01  0.00000000e+00\n",
      "   0.00000000e+00  5.25293890e-02 -3.93058967e-01 -2.02068459e-01\n",
      "  -2.64544254e-01  0.00000000e+00  1.89701367e-01 -7.54483498e-02\n",
      "   0.00000000e+00 -4.87267107e-01  2.59008611e-01 -2.80250820e-01\n",
      "  -3.28922758e-01 -3.83599840e-01 -8.22376131e-01 -0.00000000e+00\n",
      "   3.86248783e-02  0.00000000e+00 -6.80459893e-02  3.46351116e-01]\n",
      " [ 9.20465029e-03  3.13977517e-01  0.00000000e+00  7.24061119e-02\n",
      "   1.19025468e-01 -2.53023782e-01  3.59273683e-02  8.26288816e-02\n",
      "  -0.00000000e+00  5.37375399e-01 -5.33234937e-01  0.00000000e+00\n",
      "  -9.88150507e-02 -5.63768763e-01 -1.22017104e-01 -0.00000000e+00\n",
      "  -2.68662776e-01  1.75602275e-01  0.00000000e+00 -4.27351478e-01\n",
      "  -2.75702192e-01 -0.00000000e+00 -0.00000000e+00 -1.23408794e-01\n",
      "  -7.77622368e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "   1.47501343e-01 -4.01796796e-02 -1.09793293e-02  8.20974247e-02]\n",
      " [-0.00000000e+00 -3.15372469e-01  3.27469878e-01  0.00000000e+00\n",
      "   0.00000000e+00  3.25517442e-01  2.00421052e-01 -2.07135244e-02\n",
      "   0.00000000e+00  0.00000000e+00  4.77452677e-01  1.48240195e-01\n",
      "  -2.25344243e-01  0.00000000e+00  0.00000000e+00  1.63268993e-01\n",
      "   0.00000000e+00 -6.44444670e-01  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -4.84617303e-01 -0.00000000e+00\n",
      "  -0.00000000e+00  1.52818239e-02 -1.01376839e-01 -2.22857450e-02\n",
      "  -1.55380584e-01 -3.55845243e-01  0.00000000e+00 -1.80660094e-02]\n",
      " [-0.00000000e+00 -1.15859847e-01 -2.91553521e-01 -1.52386943e-01\n",
      "  -1.48946666e-02  0.00000000e+00 -1.55963040e-01 -2.54262517e-01\n",
      "  -0.00000000e+00 -9.59710097e-02  1.27873284e-01 -3.52949291e-01\n",
      "   1.74617879e-01  4.95043595e-01  3.13050458e-01 -2.63917210e-01\n",
      "  -1.97359963e-01 -2.67121824e-01  0.00000000e+00  3.07026829e-01\n",
      "   1.85010567e-01 -1.81687148e-01  2.53498083e-01 -0.00000000e+00\n",
      "   4.13276536e-01  0.00000000e+00  8.77018320e-02 -1.51714109e-01\n",
      "   2.00661567e-02 -0.00000000e+00  1.48440121e-01 -0.00000000e+00]]\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "0.0053967168\n",
      "0.001:[[-1.10993285e-01  1.93761308e-01  7.53003279e-02  2.41353727e-01\n",
      "  -0.00000000e+00  0.00000000e+00 -3.70058992e-01 -0.00000000e+00\n",
      "   7.75015583e-02 -0.00000000e+00  0.00000000e+00 -4.05727123e-01\n",
      "   3.89965828e-01 -1.69260579e-02  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  4.97711702e-01  4.31083572e-01\n",
      "   0.00000000e+00  0.00000000e+00  3.41979422e-01 -3.64278074e-01\n",
      "   0.00000000e+00 -0.00000000e+00  0.00000000e+00  8.42734601e-02\n",
      "   0.00000000e+00  0.00000000e+00  1.67757755e-01 -1.01598882e-01]\n",
      " [-0.00000000e+00 -0.00000000e+00  0.00000000e+00  6.62141686e-01\n",
      "   0.00000000e+00  1.48481934e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -6.04433016e-01  0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.53935930e-01  0.00000000e+00  0.00000000e+00  6.11130638e-02\n",
      "   1.57629024e-02  0.00000000e+00 -4.14604838e-01 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [ 9.86084130e-02 -3.96385119e-01 -1.32521675e-01  0.00000000e+00\n",
      "   0.00000000e+00 -3.62988868e-01  1.57533910e-01 -1.92921601e-02\n",
      "  -3.52158116e-01  0.00000000e+00 -0.00000000e+00 -1.24724230e-01\n",
      "  -7.17695185e-01  6.61465377e-01 -0.00000000e+00  0.00000000e+00\n",
      "  -8.15550580e-03  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  -1.87581873e-01 -4.49173902e-01 -6.75466902e-01  1.51559209e-01\n",
      "  -2.80258021e-01  0.00000000e+00  1.27664531e-02 -0.00000000e+00\n",
      "  -1.66263287e-01  1.18595554e-01 -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -4.07811616e-01 -0.00000000e+00  0.00000000e+00\n",
      "   9.42077287e-02  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  -4.88886568e-01  0.00000000e+00 -3.93033896e-02 -0.00000000e+00\n",
      "  -3.68403039e-01 -2.99476447e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  1.36650019e-01 -0.00000000e+00\n",
      "   3.67516599e-01 -5.39837698e-03 -1.10837033e-01  0.00000000e+00\n",
      "   1.44015755e-01  0.00000000e+00 -1.72804978e-01  2.34692747e-01\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.62380978e-01 -0.00000000e+00  0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -2.36661377e-01  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  1.90355768e-03  0.00000000e+00\n",
      "   0.00000000e+00  5.50688488e-04  0.00000000e+00  1.04024016e-01\n",
      "   0.00000000e+00 -1.78233586e-01 -1.00717118e-01 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -6.64115537e-02]\n",
      " [-2.93124090e-02  0.00000000e+00  1.21187845e-01  0.00000000e+00\n",
      "   0.00000000e+00 -3.85617837e-01  0.00000000e+00 -3.64157346e-01\n",
      "   0.00000000e+00  0.00000000e+00  7.21622302e-02  0.00000000e+00\n",
      "   0.00000000e+00  6.51539689e-01 -0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  2.88918811e-01  0.00000000e+00  9.72809718e-02\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  2.50716858e-01 -0.00000000e+00 -0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00  2.46589465e-01  6.18772565e-02\n",
      "   1.14720651e-01  2.79146134e-01 -2.81464226e-01 -1.61385075e-01\n",
      "  -1.04721132e-02 -5.57880706e-02  0.00000000e+00  8.29559906e-02\n",
      "  -0.00000000e+00  2.32320727e-01  2.62017793e-02  2.15771160e-01\n",
      "   0.00000000e+00  0.00000000e+00  1.89891704e-01  4.82785494e-01\n",
      "   2.02581446e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -1.86737351e-01 -0.00000000e+00  1.46341614e-01 -2.69373575e-01\n",
      "  -0.00000000e+00 -5.59994966e-02 -0.00000000e+00 -1.82997318e-01]\n",
      " [-0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -4.28236217e-01 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   1.70953887e-01 -0.00000000e+00  1.41018066e-01 -0.00000000e+00\n",
      "   1.32501473e+00  0.00000000e+00 -0.00000000e+00 -5.89339764e-01\n",
      "  -0.00000000e+00 -7.34373398e-02 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  9.67400444e-02  4.11900916e-01\n",
      "   0.00000000e+00  1.76641855e-01  1.83396205e-01  0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  2.72990737e-02 -0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -4.89671503e-01 -2.84793214e-01  2.98345722e-02\n",
      "  -1.63687702e-01 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.07999655e-03\n",
      "  -7.87258328e-01  0.00000000e+00 -1.76408858e-01  0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00  4.70614776e-02\n",
      "  -2.27706623e-01 -0.00000000e+00  2.59345953e-01 -0.00000000e+00\n",
      "  -1.74946460e-01  4.51970149e-01  7.39170208e-02 -0.00000000e+00]\n",
      " [-8.06018470e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "   2.96065012e-01  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00  6.12095601e-01\n",
      "   0.00000000e+00  1.21702798e-02 -0.00000000e+00  2.54143084e-02\n",
      "   1.58909764e-01 -0.00000000e+00 -6.01394847e-02  0.00000000e+00\n",
      "   6.74922429e-02  9.02493733e-03 -0.00000000e+00  6.59201842e-05\n",
      "   3.47906389e-01 -3.59458234e-01  0.00000000e+00 -2.17785019e-02\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      " [ 1.20912880e-01  0.00000000e+00 -0.00000000e+00 -1.54828575e-01\n",
      "  -7.06558001e-02  5.14947075e-02 -2.24732849e-01  3.07539137e-01\n",
      "   2.18612295e-03  0.00000000e+00  3.01954417e-01  0.00000000e+00\n",
      "   3.42238723e-01  0.00000000e+00  1.63692376e-02 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -1.65763719e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.73196099e-01 -0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00  1.26083528e-01 -8.98674931e-02\n",
      "   0.00000000e+00 -3.20002805e-01  0.00000000e+00  1.19212372e-01]\n",
      " [ 0.00000000e+00  2.43749020e-02  0.00000000e+00  4.91222249e-02\n",
      "  -6.42145537e-02  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00 -2.67069412e-01 -0.00000000e+00 -1.60213087e-01\n",
      "   0.00000000e+00  0.00000000e+00 -0.00000000e+00 -1.15198768e-01\n",
      "   0.00000000e+00 -2.74293677e-01  0.00000000e+00  0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.08898855e-01\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [-2.57641908e-01 -0.00000000e+00  0.00000000e+00 -3.66935728e-02\n",
      "  -4.51164251e-01  2.58905338e-01 -0.00000000e+00  1.42472473e-02\n",
      "   3.60451160e-02 -3.93594820e-02  5.76551288e-01 -0.00000000e+00\n",
      "   0.00000000e+00 -1.74897856e-01  5.08456384e-01  0.00000000e+00\n",
      "   2.61685025e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00 -3.12659910e-01  0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.57655177e-01 -0.00000000e+00 -4.17431255e-01 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.47147986e-01 -2.13825619e-01\n",
      "  -4.30709291e-01  0.00000000e+00 -0.00000000e+00  3.53672067e-01\n",
      "   1.98670296e-01 -6.87530727e-03 -3.15208301e-01 -0.00000000e+00\n",
      "  -0.00000000e+00  4.32053178e-01 -1.88754042e-01  0.00000000e+00\n",
      "  -1.57271167e-02 -0.00000000e+00 -0.00000000e+00 -7.12999416e-01\n",
      "  -0.00000000e+00  0.00000000e+00 -1.21171036e-01  1.34299694e-01]\n",
      " [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.56325534e-01\n",
      "  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00  9.18767185e-02 -0.00000000e+00 -2.25243685e-03\n",
      "  -8.82710523e-01  0.00000000e+00 -3.74327031e-01  4.14875734e-01\n",
      "   0.00000000e+00 -0.00000000e+00 -3.50077451e-01 -0.00000000e+00\n",
      "  -7.47284925e-02  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  -1.59776204e-01 -0.00000000e+00 -0.00000000e+00 -7.45438242e-02\n",
      "  -1.36307785e-01  0.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      " [ 1.14686500e-01  4.89473033e-02  1.10817174e-01  0.00000000e+00\n",
      "  -1.92318355e-02 -8.54787970e-02  1.98913287e-01  3.43314435e-02\n",
      "   8.14529215e-01 -1.66885600e-01  0.00000000e+00  1.90485083e-01\n",
      "   0.00000000e+00  0.00000000e+00 -1.26288467e-02 -0.00000000e+00\n",
      "  -4.29398659e-03 -1.29058941e-01 -3.26906182e-01 -2.25561256e-01\n",
      "  -3.29910945e-01  3.51668681e-01  3.04136753e-01  0.00000000e+00\n",
      "  -9.84381857e-02  1.42887103e-01  0.00000000e+00  4.90558724e-02\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.59154117e-02  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -1.54825059e-01  0.00000000e+00\n",
      "  -2.07019545e-01 -9.32625766e-02 -0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -3.87955624e-02 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -1.55465760e-01  0.00000000e+00 -0.00000000e+00\n",
      "  -4.10403121e-02 -2.15543938e-01 -2.34871701e-01 -0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -0.00000000e+00  2.05031678e-01]\n",
      " [ 0.00000000e+00  3.26205334e-01  0.00000000e+00  7.97374125e-02\n",
      "   1.62388457e-02 -1.39639386e-01  1.21434593e-01  0.00000000e+00\n",
      "   0.00000000e+00  4.61467686e-01 -6.04468089e-01  7.39708743e-02\n",
      "  -0.00000000e+00 -6.82922116e-01 -1.34330043e-02 -8.77594799e-02\n",
      "  -1.16570957e-01  1.24983812e-01  4.12741026e-02 -5.06807538e-01\n",
      "  -3.33675641e-01 -0.00000000e+00  0.00000000e+00 -2.08170003e-01\n",
      "  -0.00000000e+00  0.00000000e+00 -5.87394264e-02  0.00000000e+00\n",
      "   9.61986760e-02 -0.00000000e+00 -3.96317310e-02  1.35868343e-02]\n",
      " [-0.00000000e+00 -3.46359495e-01  3.12093738e-01 -0.00000000e+00\n",
      "   0.00000000e+00  2.66665426e-01  1.95788933e-01 -8.24123421e-02\n",
      "   3.85834375e-02  1.83392475e-01  4.48049295e-01  0.00000000e+00\n",
      "  -1.67750284e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -6.14093435e-01 -0.00000000e+00 -0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -6.32750855e-01 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00 -4.02484688e-02 -0.00000000e+00\n",
      "  -0.00000000e+00 -3.47531308e-01 -0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -0.00000000e+00 -2.13053934e-01 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00 -2.92550664e-03 -1.55858633e-01\n",
      "   0.00000000e+00  0.00000000e+00  9.78385345e-02 -1.19597607e-01\n",
      "   1.80396993e-01  2.80418378e-01  5.77368877e-01 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  2.51149511e-01\n",
      "   8.39865099e-03 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   5.89146699e-01  0.00000000e+00  1.21459069e-01 -3.57734346e-02\n",
      "   0.00000000e+00 -0.00000000e+00  1.28125244e-01 -6.90617038e-02]]\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "0.0072430843\n",
      "0.01:[[-0.14635485  0.05652901  0.          0.0769703  -0.          0.\n",
      "  -0.18968871 -0.          0.         -0.         -0.         -0.24505884\n",
      "   0.29745445  0.          0.18116402 -0.         -0.          0.\n",
      "   0.48894579  0.38702839  0.         -0.10685374  0.04494375 -0.1309641\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.11505155 -0.08942614]\n",
      " [-0.         -0.         -0.          0.10642106  0.          0.01071007\n",
      "  -0.          0.         -0.         -0.         -0.         -0.\n",
      "  -0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.         -0.         -0.\n",
      "   0.         -0.          0.         -0.          0.         -0.\n",
      "   0.         -0.        ]\n",
      " [ 0.         -0.         -0.          0.         -0.         -0.05564506\n",
      "   0.         -0.         -0.          0.         -0.         -0.\n",
      "  -0.          0.0091387  -0.          0.         -0.         -0.\n",
      "  -0.          0.         -0.         -0.         -0.          0.\n",
      "  -0.          0.          0.         -0.         -0.          0.\n",
      "  -0.         -0.        ]\n",
      " [-0.         -0.         -0.          0.          0.          0.\n",
      "   0.          0.         -0.         -0.         -0.          0.\n",
      "  -0.         -0.          0.         -0.          0.          0.\n",
      "   0.          0.          0.         -0.         -0.          0.\n",
      "   0.          0.         -0.          0.          0.         -0.\n",
      "   0.         -0.        ]\n",
      " [-0.         -0.         -0.          0.         -0.          0.\n",
      "  -0.          0.         -0.12479635 -0.         -0.         -0.0084101\n",
      "  -0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.         -0.01524785 -0.\n",
      "  -0.          0.          0.         -0.         -0.          0.\n",
      "   0.         -0.        ]\n",
      " [-0.          0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "   0.          0.         -0.          0.         -0.         -0.\n",
      "  -0.         -0.         -0.          0.          0.          0.\n",
      "  -0.         -0.          0.         -0.         -0.          0.\n",
      "  -0.          0.        ]\n",
      " [-0.         -0.          0.          0.          0.          0.\n",
      "  -0.         -0.         -0.         -0.         -0.          0.\n",
      "  -0.          0.          0.          0.          0.          0.\n",
      "   0.          0.09800864  0.         -0.         -0.         -0.\n",
      "   0.         -0.          0.         -0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [-0.          0.          0.          0.         -0.         -0.\n",
      "   0.         -0.          0.         -0.         -0.          0.\n",
      "   0.63720174  0.          0.         -0.2958135  -0.         -0.\n",
      "  -0.          0.         -0.         -0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [ 0.          0.         -0.         -0.         -0.         -0.\n",
      "  -0.          0.         -0.         -0.          0.         -0.\n",
      "   0.          0.02583298  0.          0.         -0.          0.\n",
      "  -0.          0.         -0.         -0.          0.          0.\n",
      "  -0.         -0.          0.         -0.         -0.          0.\n",
      "   0.          0.        ]\n",
      " [-0.          0.          0.          0.          0.07482581  0.\n",
      "  -0.         -0.         -0.         -0.          0.          0.27851202\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "  -0.          0.          0.          0.         -0.          0.\n",
      "   0.         -0.05338794  0.         -0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [ 0.          0.         -0.         -0.         -0.          0.\n",
      "  -0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.          0.          0.          0.         -0.\n",
      "  -0.         -0.         -0.          0.          0.         -0.\n",
      "   0.         -0.         -0.         -0.          0.         -0.\n",
      "  -0.          0.        ]\n",
      " [-0.          0.          0.          0.         -0.         -0.\n",
      "  -0.         -0.          0.         -0.         -0.         -0.\n",
      "   0.          0.          0.         -0.         -0.         -0.\n",
      "   0.          0.         -0.         -0.          0.         -0.\n",
      "  -0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -0.          0.\n",
      "  -0.          0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "  -0.          0.          0.          0.          0.         -0.\n",
      "   0.          0.         -0.         -0.         -0.         -0.\n",
      "   0.          0.        ]\n",
      " [ 0.03049738 -0.15946237 -0.09664757 -0.         -0.         -0.\n",
      "   0.          0.         -0.          0.          0.         -0.\n",
      "  -0.51823687 -0.         -0.          0.32764509  0.         -0.\n",
      "  -0.29553435 -0.         -0.          0.         -0.19397247  0.\n",
      "  -0.         -0.         -0.         -0.47990657 -0.         -0.\n",
      "  -0.          0.        ]\n",
      " [ 0.         -0.         -0.         -0.39768348  0.         -0.\n",
      "   0.          0.         -0.          0.          0.         -0.\n",
      "  -1.18195405  0.         -0.21917447  0.25592467  0.         -0.\n",
      "  -0.28380174 -0.1011885  -0.14713451  0.         -0.37456023  0.\n",
      "  -0.32044629  0.         -0.         -0.05404021 -0.         -0.\n",
      "  -0.          0.01170514]\n",
      " [ 0.          0.          0.         -0.         -0.         -0.\n",
      "   0.1637847   0.          0.6755621  -0.         -0.          0.00645763\n",
      "   0.         -0.         -0.         -0.         -0.         -0.\n",
      "  -0.18714728 -0.29013029 -0.20021992  0.27125583  0.03175289  0.01688527\n",
      "  -0.07456071  0.04419371  0.          0.         -0.         -0.\n",
      "  -0.          0.        ]\n",
      " [ 0.          0.          0.         -0.          0.         -0.\n",
      "  -0.         -0.         -0.         -0.         -0.          0.\n",
      "   0.          0.         -0.          0.         -0.          0.\n",
      "  -0.         -0.         -0.         -0.          0.         -0.\n",
      "  -0.         -0.         -0.         -0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.04437958 -0.          0.         -0.\n",
      "   0.         -0.          0.          0.13760725 -0.          0.\n",
      "  -0.         -0.20703127 -0.0933302  -0.         -0.         -0.\n",
      "  -0.         -0.4494513  -0.248183    0.          0.         -0.\n",
      "  -0.          0.         -0.          0.          0.         -0.\n",
      "  -0.          0.        ]\n",
      " [ 0.         -0.          0.         -0.          0.          0.\n",
      "   0.31129371 -0.          0.          0.28141789  0.08349385  0.\n",
      "  -0.         -0.         -0.          0.          0.         -0.28210349\n",
      "  -0.         -0.         -0.          0.02905818 -0.11316669  0.\n",
      "  -0.          0.         -0.         -0.         -0.         -0.20879298\n",
      "  -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.         -0.          0.\n",
      "  -0.         -0.         -0.         -0.          0.         -0.\n",
      "   0.          0.          0.04282238 -0.         -0.          0.\n",
      "   0.          0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]]\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "0.019468091\n",
      "0.1:[[-0.          0.          0.          0.         -0.          0.\n",
      "  -0.         -0.         -0.         -0.         -0.         -0.\n",
      "   0.          0.          0.         -0.         -0.          0.\n",
      "   0.          0.          0.         -0.          0.         -0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [-0.         -0.         -0.          0.          0.          0.\n",
      "  -0.          0.         -0.         -0.         -0.         -0.\n",
      "   0.          0.          0.         -0.          0.          0.\n",
      "   0.          0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [ 0.         -0.         -0.         -0.         -0.         -0.\n",
      "   0.         -0.         -0.          0.         -0.         -0.\n",
      "  -0.          0.         -0.          0.         -0.         -0.\n",
      "  -0.         -0.         -0.         -0.         -0.          0.\n",
      "  -0.          0.          0.         -0.         -0.          0.\n",
      "  -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.          0.          0.\n",
      "   0.          0.         -0.         -0.         -0.          0.\n",
      "   0.         -0.          0.         -0.          0.          0.\n",
      "   0.          0.          0.         -0.         -0.          0.\n",
      "   0.          0.         -0.          0.          0.         -0.\n",
      "   0.         -0.        ]\n",
      " [-0.         -0.         -0.          0.         -0.          0.\n",
      "  -0.          0.         -0.         -0.         -0.         -0.\n",
      "  -0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.         -0.         -0.\n",
      "   0.         -0.          0.         -0.         -0.          0.\n",
      "   0.         -0.        ]\n",
      " [-0.          0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "  -0.          0.         -0.          0.         -0.         -0.\n",
      "  -0.         -0.         -0.          0.         -0.          0.\n",
      "  -0.         -0.          0.         -0.         -0.          0.\n",
      "  -0.          0.        ]\n",
      " [-0.          0.          0.          0.          0.          0.\n",
      "  -0.         -0.         -0.         -0.         -0.          0.\n",
      "   0.          0.          0.         -0.          0.          0.\n",
      "   0.          0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [-0.          0.          0.          0.         -0.         -0.\n",
      "  -0.         -0.          0.         -0.         -0.         -0.\n",
      "   0.          0.          0.         -0.         -0.          0.\n",
      "   0.          0.         -0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [ 0.         -0.         -0.         -0.          0.         -0.\n",
      "  -0.          0.         -0.         -0.          0.         -0.\n",
      "  -0.          0.          0.          0.         -0.          0.\n",
      "  -0.          0.          0.         -0.          0.          0.\n",
      "  -0.         -0.          0.         -0.         -0.          0.\n",
      "   0.          0.        ]\n",
      " [-0.          0.          0.          0.          0.          0.\n",
      "  -0.         -0.         -0.         -0.         -0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.          0.         -0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [ 0.          0.         -0.         -0.         -0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "  -0.         -0.         -0.          0.          0.         -0.\n",
      "  -0.         -0.         -0.          0.          0.          0.\n",
      "  -0.         -0.         -0.         -0.          0.         -0.\n",
      "  -0.          0.        ]\n",
      " [-0.          0.          0.          0.         -0.         -0.\n",
      "  -0.         -0.          0.         -0.         -0.         -0.\n",
      "   0.          0.          0.         -0.         -0.          0.\n",
      "   0.          0.          0.         -0.          0.         -0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -0.          0.\n",
      "  -0.          0.         -0.         -0.          0.         -0.\n",
      "  -0.         -0.          0.          0.          0.          0.\n",
      "  -0.          0.          0.          0.         -0.         -0.\n",
      "   0.          0.         -0.         -0.         -0.         -0.\n",
      "   0.          0.        ]\n",
      " [ 0.         -0.         -0.         -0.         -0.         -0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "  -0.          0.         -0.          0.          0.         -0.\n",
      "  -0.         -0.         -0.          0.         -0.          0.\n",
      "  -0.          0.         -0.         -0.         -0.         -0.\n",
      "  -0.          0.        ]\n",
      " [ 0.         -0.         -0.         -0.          0.         -0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "  -0.02068032 -0.         -0.          0.          0.         -0.\n",
      "  -0.         -0.         -0.          0.         -0.          0.\n",
      "  -0.          0.         -0.         -0.         -0.         -0.\n",
      "  -0.          0.        ]\n",
      " [ 0.          0.          0.         -0.         -0.         -0.\n",
      "   0.          0.          0.         -0.          0.          0.\n",
      "  -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.          0.          0.          0.\n",
      "  -0.          0.          0.         -0.         -0.         -0.\n",
      "  -0.          0.        ]\n",
      " [-0.          0.          0.         -0.          0.         -0.\n",
      "  -0.         -0.         -0.         -0.         -0.          0.\n",
      "   0.          0.         -0.         -0.         -0.          0.\n",
      "   0.         -0.         -0.         -0.          0.         -0.\n",
      "  -0.         -0.         -0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.         -0.         -0.         -0.\n",
      "   0.         -0.          0.          0.         -0.          0.\n",
      "  -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.          0.         -0.         -0.\n",
      "  -0.          0.         -0.          0.          0.         -0.\n",
      "  -0.          0.        ]\n",
      " [ 0.         -0.          0.         -0.          0.          0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "  -0.         -0.         -0.          0.          0.         -0.\n",
      "  -0.         -0.         -0.          0.         -0.          0.\n",
      "  -0.          0.         -0.         -0.         -0.         -0.\n",
      "  -0.          0.        ]\n",
      " [-0.          0.         -0.          0.         -0.          0.\n",
      "  -0.         -0.         -0.         -0.          0.         -0.\n",
      "   0.          0.          0.         -0.         -0.          0.\n",
      "   0.          0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.          0.          0.\n",
      "   0.         -0.        ]]\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "125/125 [==============================] - 0s 912us/step\n",
      "0.031644244\n",
      "1:[[-0.  0.  0.  0. -0.  0. -0. -0. -0. -0. -0. -0.  0.  0.  0. -0. -0.  0.\n",
      "   0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      " [-0. -0. -0.  0.  0.  0. -0.  0. -0. -0. -0. -0.  0.  0.  0. -0.  0.  0.\n",
      "   0.  0.  0. -0.  0. -0.  0. -0.  0.  0.  0.  0.  0. -0.]\n",
      " [ 0. -0. -0. -0. -0. -0.  0. -0. -0.  0. -0. -0. -0.  0. -0.  0. -0. -0.\n",
      "  -0. -0. -0. -0. -0.  0. -0.  0.  0. -0. -0.  0. -0.  0.]\n",
      " [-0. -0. -0.  0.  0.  0.  0.  0. -0. -0. -0.  0.  0. -0.  0. -0.  0.  0.\n",
      "   0.  0.  0. -0. -0.  0.  0.  0. -0.  0.  0. -0.  0. -0.]\n",
      " [-0. -0. -0.  0. -0.  0. -0.  0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0. -0. -0. -0.  0. -0.  0. -0. -0.  0.  0. -0.]\n",
      " [-0.  0.  0. -0.  0. -0.  0. -0.  0.  0.  0.  0. -0.  0. -0.  0. -0. -0.\n",
      "  -0. -0. -0.  0. -0.  0. -0. -0.  0. -0. -0.  0. -0.  0.]\n",
      " [-0.  0.  0.  0.  0.  0. -0. -0. -0. -0. -0.  0.  0.  0.  0. -0.  0.  0.\n",
      "   0.  0.  0. -0.  0. -0.  0. -0.  0.  0.  0.  0.  0. -0.]\n",
      " [-0.  0.  0.  0. -0. -0. -0. -0.  0. -0. -0. -0.  0.  0.  0. -0. -0.  0.\n",
      "   0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      " [ 0. -0. -0. -0.  0. -0. -0.  0. -0. -0.  0. -0. -0.  0.  0.  0. -0.  0.\n",
      "  -0.  0.  0. -0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.]\n",
      " [-0.  0.  0.  0.  0.  0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0. -0.  0. -0.  0.  0.  0. -0.]\n",
      " [ 0.  0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0. -0. -0.  0.  0. -0.\n",
      "  -0. -0. -0.  0.  0.  0. -0. -0. -0. -0.  0. -0. -0.  0.]\n",
      " [-0.  0.  0.  0. -0. -0. -0. -0.  0. -0. -0. -0.  0.  0.  0. -0. -0.  0.\n",
      "   0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      " [-0. -0. -0. -0. -0.  0. -0.  0. -0. -0.  0. -0. -0. -0.  0.  0.  0.  0.\n",
      "  -0.  0.  0.  0. -0. -0.  0.  0. -0. -0. -0. -0.  0.  0.]\n",
      " [ 0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0. -0.  0. -0.  0.  0. -0.\n",
      "  -0. -0. -0.  0. -0.  0. -0.  0. -0. -0. -0. -0. -0.  0.]\n",
      " [ 0. -0. -0. -0.  0. -0.  0.  0.  0.  0.  0.  0. -0. -0. -0.  0.  0. -0.\n",
      "  -0. -0. -0.  0. -0.  0. -0.  0. -0. -0. -0. -0. -0.  0.]\n",
      " [ 0.  0.  0. -0. -0. -0.  0.  0.  0. -0.  0.  0. -0. -0. -0. -0. -0. -0.\n",
      "  -0. -0. -0.  0.  0.  0. -0.  0.  0. -0. -0. -0. -0.  0.]\n",
      " [-0.  0.  0. -0.  0. -0. -0. -0. -0. -0. -0.  0.  0.  0. -0. -0. -0.  0.\n",
      "   0. -0. -0. -0.  0. -0. -0. -0. -0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -0. -0. -0.  0. -0.  0.  0. -0.  0. -0. -0. -0. -0. -0. -0.\n",
      "  -0. -0. -0.  0. -0. -0. -0.  0. -0.  0.  0. -0. -0.  0.]\n",
      " [ 0. -0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0. -0. -0. -0.  0.  0. -0.\n",
      "  -0. -0. -0.  0. -0.  0. -0.  0. -0. -0. -0. -0. -0.  0.]\n",
      " [-0.  0. -0.  0. -0.  0. -0. -0. -0. -0.  0. -0.  0.  0.  0. -0. -0.  0.\n",
      "   0.  0.  0. -0.  0. -0.  0. -0.  0.  0.  0.  0.  0. -0.]]\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "0.031644244\n"
     ]
    }
   ],
   "source": [
    "lamda = [0 , 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "test_loss_aaa = []\n",
    "test_loss_train = []\n",
    "w = []\n",
    "\n",
    "for i in lamda:\n",
    "    la = Lasso(alpha=i,max_iter=100000)\n",
    "    la.fit(xa_new,aa_1)\n",
    "    w = (la.coef_.T)\n",
    "    b = la.intercept_\n",
    "    weight_shape = (20, 32)  # Expected shape of the weight\n",
    "    bias_shape = (32,)\n",
    "    weight = np.array(w).reshape(weight_shape)\n",
    "    bias = np.array(b).reshape(bias_shape)\n",
    "    c_w = [weight, bias]\n",
    "    \n",
    "\n",
    "    autoencoder.decoder.layers[0].set_weights(c_w)\n",
    "    print(f'{i}:{w}')\n",
    "\n",
    "    #autoencoder.decoder.layers[0].trainable = False  \n",
    "\n",
    "    #autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    #autoencoder.fit(Xa_train,Xa_train,epochs=500,batch_size=32,verbose=0)\n",
    "    re_a = autoencoder.predict(Xa_test)\n",
    "    test_loss_aaa.append(np.mean(tf.keras.losses.mae(re_a, Xa_test)))  \n",
    "\n",
    "    re_train = autoencoder.predict(Xa_train)\n",
    "    test_loss_train = tf.keras.losses.mae(re_train, Xa_train)\n",
    "    print(np.mean(test_loss_train))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0053275838, 0.005442526, 0.0072445255, 0.019591725, 0.03206804, 0.03206804]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_loss_aaa)\n",
    "plt.plot(lamda,test_loss_aaa)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('log($\\\\lambda$)')\n",
    "plt.ylabel('log(Test loss)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso with customized code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso_6a:\n",
    "\n",
    "    def __init__(self, alpha, epoch = 1000, weights = np.zeros(17,)):\n",
    "        self.alpha = alpha  # tuning parameter(penalty term)  \n",
    "        self.epoch =  epoch  # No. of iterations (default = 1000)\n",
    "        self.coef = None    # Weights or Co-eficients\n",
    "        self.bias = None    # Bias or intercept\n",
    "        self.weights = weights\n",
    "\n",
    "    def soft_threshold(self,rho,lamda):\n",
    "        if rho < - lamda:\n",
    "            return rho + lamda\n",
    "        elif rho > lamda:\n",
    "            return rho - lamda\n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "            X = np.column_stack((np.ones(len(X)), X))   # Training features\n",
    "            n = X.shape[0]\n",
    "            beta = copy.deepcopy(self.weights) # array of bias and weights\n",
    "            beta[0] = np.sum(y - np.dot(X[:, 1:], beta[1:])) / (X.shape[0])\n",
    "\n",
    "            for iteration in range(self.epoch):                                         \n",
    "                for j in range(1,17):                        \n",
    "                        beta[j] = 0.0                       \n",
    "                        error  = y - np.dot(X,beta)                       \n",
    "                        rho = np.dot(X[:,j], error )\n",
    "                        lamda  = self.alpha*n\n",
    "\n",
    "                        beta[j] = self.soft_threshold(rho , lamda ) / ((X[:, j]**2).sum()+1e-20) \n",
    "                        \n",
    "                        beta[0] = np.sum(y - np.dot(X[:, 1:], beta[1:])) / (X.shape[0])\n",
    "            \n",
    "            self.coef = beta[1:]\n",
    "            self.bias = beta[0]                   \n",
    "                \n",
    "            return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 626us/step\n"
     ]
    }
   ],
   "source": [
    "coeff_a = np.zeros((16,32))\n",
    "bias_a = np.zeros(32)\n",
    "\n",
    "\n",
    "for i in range (aa_1.shape[1]):\n",
    "    weights_a = np.append(bias_matrix_latent_to_decoder[i],weight_matrix_latent_to_decoder[:,i])\n",
    "    model_a = Lasso_6a(alpha=0.001,epoch=100,weights=weights_a)\n",
    "    model_a.fit(xa_new,aa_1[:,i])\n",
    "    coeff_a[:,i]= model_a.coef\n",
    "    bias_a[i] = model_a.bias\n",
    "    \n",
    "wb = [coeff_a,bias_a]   \n",
    "autoencoder.decoder.layers[0].set_weights(wb)\n",
    "re_aaa = autoencoder.predict(Xa_test)\n",
    "test_loss_lasso = (np.mean(tf.keras.losses.mae(re_aaa, Xa_test)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 613us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 763us/step\n",
      "32/32 [==============================] - 0s 763us/step\n",
      "32/32 [==============================] - 0s 790us/step\n"
     ]
    }
   ],
   "source": [
    "coeff_a = np.zeros((16,32))\n",
    "bias_a = np.zeros(32)\n",
    "test_loss_lasso = []\n",
    "\n",
    "#for loop over the neurons:\n",
    "for j in lamda:\n",
    "    for i in range (aa_1.shape[1]):\n",
    "        weights_a = np.append(bias_matrix_latent_to_decoder[i],weight_matrix_latent_to_decoder[:,i])\n",
    "        model_a = Lasso_6a(alpha=j,epoch=100,weights=weights_a)\n",
    "        model_a.fit(xa_new,aa_1[:,i])\n",
    "        coeff_a[:,i]= model_a.coef\n",
    "        bias_a[i] = model_a.bias\n",
    "    \n",
    "    wb = [coeff_a,bias_a]   \n",
    "    autoencoder.decoder.layers[0].set_weights(wb)\n",
    "    re_aaa = autoencoder.predict(Xa_test)\n",
    "    test_loss_lasso.append(np.mean(tf.keras.losses.mae(re_aaa, Xa_test)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005325243, 0.0053263237, 0.005382058, 0.00715913, 0.017914003, 0.031400297, 0.032134317, 0.032134317]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_loss_lasso)\n",
    "plt.plot(lamda,test_loss_lasso)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('log(lamda)')\n",
    "plt.ylabel('test loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
